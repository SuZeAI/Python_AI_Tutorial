{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyM8FDoCXh9cwsafMCpUeNPg"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G9H3r9wSg1b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669287969609,
     "user_tz": -420,
     "elapsed": 83456,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "2c7c2892-f6ca-4e7f-cd28-abbb59b52baa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# nltk.download('all')"
   ],
   "metadata": {
    "id": "q0lwfaSybpyQ"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# %cd /content/drive/MyDrive/AI NAVER/NLP"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Pkrod4EUhhe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288058173,
     "user_tz": -420,
     "elapsed": 6,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "1ce207c1-70e7-4ee9-ed9b-8307503eb2ee"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "QZ8YbW3UUlol",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288147627,
     "user_tz": -420,
     "elapsed": 9,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "10b043f3-23db-4e45-aba2-6b61698aba2e"
   },
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_list = []\n",
    "cities = ['boston', 'chicago', 'la', 'montreal', 'ny', 'sf', 'toronto', 'vancouver']\n",
    "for city in cities:\n",
    "    df_tmp = pd.read_pickle('./data/data_scientist_{}.pkl'.format(city))\n",
    "    df_tmp['city'] = city\n",
    "    df_list.append(df_tmp)"
   ],
   "metadata": {
    "id": "-MSgvTjAUriQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288390473,
     "user_tz": -420,
     "elapsed": 4,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_list[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3UaiOFNHVdod",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288292785,
     "user_tz": -420,
     "elapsed": 7,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "6824e76d-25b4-416c-9685-84dd7976c17b"
   },
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             job_title  \\\n0                                Junior Data Scientist   \n1                                Senior Data Scientist   \n2                                       Data Scientist   \n3                                       Data Scientist   \n4          Analyst II/Assistant Director, Data Science   \n..                                                 ...   \n800                                Senior Data Analyst   \n801  100% REMOTE Data Scientist- Healthcare Claims/...   \n802          Senior Data Scientist-Systems Engineering   \n803  Analytics, Data Scientist - Artificial Intelli...   \n804                              Junior Data Scientist   \n\n                            company  \\\n0                      Pacific Life   \n1                           Invicro   \n2                          Trillium   \n3                     ENGIE Insight   \n4          Liberty Mutual Insurance   \n..                              ...   \n800                      MassMutual   \n801                     CyberCoders   \n802  Cenergy International Services   \n803                      CVS Health   \n804                    Pacific Life   \n\n                                           location  \\\n0                                      - Boston, MA   \n1            - Boston, MA 02210 (South Boston area)   \n2    - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n3                                      - Boston, MA   \n4                                - Boston, MA 02101   \n..                                              ...   \n800                                    - Boston, MA   \n801  - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n802            - Cambridge, MA 02139 (Area IV area)   \n803              - Boston, MA 02110 (Downtown area)   \n804                                    - Boston, MA   \n\n                                       job_description    city  \n0    Purpose of Role:\\nAs part of the PLRe Retro Pr...  boston  \n1    Overview:\\nThe Senior Data Scientist will be a...  boston  \n2    Now hiring a Data Scientist in Boston, Massach...  boston  \n3    ENGIE Impact is accelerating sustainability tr...  boston  \n4    Liberty Mutual’s newly formed Global Risk Solu...  boston  \n..                                                 ...     ...  \n800  â€<â€<\\nMassMutual continues to expand its dat...  boston  \n801  100% REMOTE Data Scientist- Healthcare Claims/...  boston  \n802  Senior Data Scientist – Systems Engineering\\nT...  boston  \n803  This role will have the unique opportunity to ...  boston  \n804  Purpose of Role:\\nAs part of the PLRe Retro Pr...  boston  \n\n[805 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n      <th>company</th>\n      <th>location</th>\n      <th>job_description</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Junior Data Scientist</td>\n      <td>Pacific Life</td>\n      <td>- Boston, MA</td>\n      <td>Purpose of Role:\\nAs part of the PLRe Retro Pr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Senior Data Scientist</td>\n      <td>Invicro</td>\n      <td>- Boston, MA 02210 (South Boston area)</td>\n      <td>Overview:\\nThe Senior Data Scientist will be a...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Scientist</td>\n      <td>Trillium</td>\n      <td>- Boston, MA 02108 (Back Bay-Beacon Hill area)</td>\n      <td>Now hiring a Data Scientist in Boston, Massach...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Scientist</td>\n      <td>ENGIE Insight</td>\n      <td>- Boston, MA</td>\n      <td>ENGIE Impact is accelerating sustainability tr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Analyst II/Assistant Director, Data Science</td>\n      <td>Liberty Mutual Insurance</td>\n      <td>- Boston, MA 02101</td>\n      <td>Liberty Mutual’s newly formed Global Risk Solu...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <td>Senior Data Analyst</td>\n      <td>MassMutual</td>\n      <td>- Boston, MA</td>\n      <td>â€&lt;â€&lt;\\nMassMutual continues to expand its dat...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>801</th>\n      <td>100% REMOTE Data Scientist- Healthcare Claims/...</td>\n      <td>CyberCoders</td>\n      <td>- Boston, MA 02108 (Back Bay-Beacon Hill area)</td>\n      <td>100% REMOTE Data Scientist- Healthcare Claims/...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>Senior Data Scientist-Systems Engineering</td>\n      <td>Cenergy International Services</td>\n      <td>- Cambridge, MA 02139 (Area IV area)</td>\n      <td>Senior Data Scientist – Systems Engineering\\nT...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>Analytics, Data Scientist - Artificial Intelli...</td>\n      <td>CVS Health</td>\n      <td>- Boston, MA 02110 (Downtown area)</td>\n      <td>This role will have the unique opportunity to ...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>804</th>\n      <td>Junior Data Scientist</td>\n      <td>Pacific Life</td>\n      <td>- Boston, MA</td>\n      <td>Purpose of Role:\\nAs part of the PLRe Retro Pr...</td>\n      <td>boston</td>\n    </tr>\n  </tbody>\n</table>\n<p>805 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_list[:10]"
   ],
   "metadata": {
    "id": "GR3aVcssU1vu"
   },
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[                                             job_title  \\\n 0                                Junior Data Scientist   \n 1                                Senior Data Scientist   \n 2                                       Data Scientist   \n 3                                       Data Scientist   \n 4          Analyst II/Assistant Director, Data Science   \n ..                                                 ...   \n 800                                Senior Data Analyst   \n 801  100% REMOTE Data Scientist- Healthcare Claims/...   \n 802          Senior Data Scientist-Systems Engineering   \n 803  Analytics, Data Scientist - Artificial Intelli...   \n 804                              Junior Data Scientist   \n \n                             company  \\\n 0                      Pacific Life   \n 1                           Invicro   \n 2                          Trillium   \n 3                     ENGIE Insight   \n 4          Liberty Mutual Insurance   \n ..                              ...   \n 800                      MassMutual   \n 801                     CyberCoders   \n 802  Cenergy International Services   \n 803                      CVS Health   \n 804                    Pacific Life   \n \n                                            location  \\\n 0                                      - Boston, MA   \n 1            - Boston, MA 02210 (South Boston area)   \n 2    - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n 3                                      - Boston, MA   \n 4                                - Boston, MA 02101   \n ..                                              ...   \n 800                                    - Boston, MA   \n 801  - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n 802            - Cambridge, MA 02139 (Area IV area)   \n 803              - Boston, MA 02110 (Downtown area)   \n 804                                    - Boston, MA   \n \n                                        job_description    city  \n 0    Purpose of Role:\\nAs part of the PLRe Retro Pr...  boston  \n 1    Overview:\\nThe Senior Data Scientist will be a...  boston  \n 2    Now hiring a Data Scientist in Boston, Massach...  boston  \n 3    ENGIE Impact is accelerating sustainability tr...  boston  \n 4    Liberty Mutual’s newly formed Global Risk Solu...  boston  \n ..                                                 ...     ...  \n 800  â€<â€<\\nMassMutual continues to expand its dat...  boston  \n 801  100% REMOTE Data Scientist- Healthcare Claims/...  boston  \n 802  Senior Data Scientist – Systems Engineering\\nT...  boston  \n 803  This role will have the unique opportunity to ...  boston  \n 804  Purpose of Role:\\nAs part of the PLRe Retro Pr...  boston  \n \n [805 rows x 5 columns],\n                                              job_title  \\\n 0                                       Data Scientist   \n 1    100% REMOTE Data Scientist- Healthcare Claims/...   \n 2                    Data Scientist - Machine Learning   \n 3                                        Data Engineer   \n 4                             Associate Data Scientist   \n ..                                                 ...   \n 359                  Data Scientist - Machine Learning   \n 360                           Arity- Sr Data Scientist   \n 361  Sr. Data Scientist: Computer Vision & Deep Lea...   \n 362                              Senior Data Scientist   \n 363                   Sr Actuarial Data Scientist-Auto   \n \n                                            company  \\\n 0                                       Workbridge   \n 1                                      CyberCoders   \n 2                                      CyberCoders   \n 3        Spectrum Communications & Consulting Inc.   \n 4    Blue Cross Blue Shield of IL, MT, NM, OK & TX   \n ..                                             ...   \n 359                                    CyberCoders   \n 360                                       Allstate   \n 361                                       Allstate   \n 362                                       Allstate   \n 363                                       Allstate   \n \n                             location  \\\n 0    - Chicago, IL 60603 (Loop area)   \n 1    - Chicago, IL 60601 (Loop area)   \n 2                      - Chicago, IL   \n 3                      - Chicago, IL   \n 4                      - Chicago, IL   \n ..                               ...   \n 359                    - Chicago, IL   \n 360                    - Chicago, IL   \n 361                    - Chicago, IL   \n 362                    - Chicago, IL   \n 363                    - Chicago, IL   \n \n                                        job_description     city  \n 0    Our client located in the heart of Chicago’s b...  chicago  \n 1    100% REMOTE Data Scientist- Healthcare Claims/...  chicago  \n 2    Data Scientist - Machine Learning\\nIf you are ...  chicago  \n 3    What do incubators and Spectrum have in common...  chicago  \n 4    As part of our Government Programs Data Analyt...  chicago  \n ..                                                 ...      ...  \n 359  Data Scientist - Machine Learning\\nIf you are ...  chicago  \n 360  Founded by The Allstate Corporation in 2016, A...  chicago  \n 361  Where good people build rewarding careers.\\nTh...  chicago  \n 362  Where good people build rewarding careers.\\nTh...  chicago  \n 363  Where good people build rewarding careers.\\nTh...  chicago  \n \n [364 rows x 5 columns],\n                                              job_title  \\\n 0                                  STATISTICAL ANALYST   \n 1                            Machine Learning Engineer   \n 2                                  Senior Statistician   \n 3                                Senior Data Scientist   \n 4                                  Junior Statistician   \n ..                                                 ...   \n 321                      DEAN OF MATHEMATICAL SCIENCES   \n 322   AI/ML Cloud Deployment Engineer- Senior Engineer   \n 323  Artificial Intelligence, Senior Manager - Appl...   \n 324  Artificial Intelligence, Senior Consultant - A...   \n 325  AI/ML Cloud Deployment Engineer - Senior Archi...   \n \n                               company  \\\n 0    California FAIR Plan Association   \n 1                          Triplebyte   \n 2                         UCLA Health   \n 3                 Just Auto Insurance   \n 4                         UCLA Health   \n ..                                ...   \n 321                 El Camino College   \n 322                          Deloitte   \n 323                          Deloitte   \n 324                          Deloitte   \n 325                          Deloitte   \n \n                                      location  \\\n 0    - Los Angeles, CA 90010 (Koreatown area)   \n 1                           - Los Angeles, CA   \n 2       - Los Angeles, CA 91403 (Encino area)   \n 3                     - Los Angeles, CA 90079   \n 4       - Los Angeles, CA 91403 (Encino area)   \n ..                                        ...   \n 321                      - Torrance, CA 90506   \n 322   - Los Angeles, CA 90013 (Downtown area)   \n 323   - Los Angeles, CA 90013 (Downtown area)   \n 324   - Los Angeles, CA 90013 (Downtown area)   \n 325   - Los Angeles, CA 90013 (Downtown area)   \n \n                                        job_description city  \n 0    Position Summary:\\nThe Statistical Analyst ass...   la  \n 1    About Triplebyte\\nTriplebyte is transforming t...   la  \n 2    Responsibilities\\nDeliver critical support wit...   la  \n 3    Just Auto Insurance (Just) is a young, fast-gr...   la  \n 4    Responsibilities\\nUnder supervision of the Pri...   la  \n ..                                                 ...  ...  \n 321  The Dean of Mathematical Science will head a d...   la  \n 322  The team\\nCloud Engineering\\nOur Cloud Enginee...   la  \n 323  Artificial Intelligence, Senior Manager - Appl...   la  \n 324  Artificial Intelligence, Senior Consultant - A...   la  \n 325  The team\\nOur Cloud Engineering team focuses o...   la  \n \n [326 rows x 5 columns],\n                                          job_title  \\\n 0                                   Data Scientist   \n 1                       Data Engineering Architect   \n 2                            Instrument Technician   \n 3      Sr. Software Developer - Computer Scientist   \n 4    Data Scientist for the Data & Analytics Group   \n ..                                             ...   \n 217                Project Manager - Environmental   \n 218    Project Manager - Drug Development Projects   \n 219          Administrative Assistant - Sales team   \n 220    Sr. Software Developer - Computer Scientist   \n 221                     Data Engineering Architect   \n \n                          company             location  \\\n 0         Intelius Analytics Ltd       - Montréal, QC   \n 1                       Ericsson       - Montréal, QC   \n 2            Nuchem Therapeutics       - Montréal, QC   \n 3               Liquid Analytics       - Montréal, QC   \n 4                    KPI Digital  - Saint-Laurent, QC   \n ..                           ...                  ...   \n 217  Bureau Veritas Laboratories  - Saint-Laurent, QC   \n 218                      Certara       - Montréal, QC   \n 219  Bureau Veritas Laboratories  - Saint-Laurent, QC   \n 220             Liquid Analytics       - Montréal, QC   \n 221                     Ericsson       - Montréal, QC   \n \n                                        job_description      city  \n 0    Intelius Analytics is seeking enthusiastic ind...  montreal  \n 1    Ericsson est le premier fournisseur mondial de...  montreal  \n 2    Nuchem Therapeutics, a Medicinal Chemistry and...  montreal  \n 3    Liquid Analytics: Experience your AI. We are a...  montreal  \n 4    About KPI:\\nKPI Digital has been helping clien...  montreal  \n ..                                                 ...       ...  \n 217  Do you believe in the power of teamwork and sh...  montreal  \n 218  Certara is hiring a Project Manager in Raleigh...  montreal  \n 219  Do you believe in the power of teamwork and sh...  montreal  \n 220  Liquid Analytics: Experience your AI. We are a...  montreal  \n 221  Ericsson est le premier fournisseur mondial de...  montreal  \n \n [222 rows x 5 columns],\n                                              job_title  \\\n 0                            Machine Learning Engineer   \n 1       Data Science/ML engineer with specialty in NLP   \n 2                                  Senior Data Analyst   \n 3                         Data Scientist (NLP Focused)   \n 4                                 Data Science Manager   \n ..                                                 ...   \n 964                       Data Scientist (NLP Focused)   \n 965                                     Data Scientist   \n 966  Data Science Full-Time Student Opportunity (Gr...   \n 967     Data Science/ML engineer with specialty in NLP   \n 968                        Data Science Specialist USA   \n \n                            company  \\\n 0                       Triplebyte   \n 1               Transport Learning   \n 2                 Ready Responders   \n 3                         Fakespot   \n 4                  Biz2Credit Inc.   \n ..                             ...   \n 964                       Fakespot   \n 965  Strategic Financial Solutions   \n 966                     CVS Health   \n 967             Transport Learning   \n 968                        Mphasis   \n \n                                            location  \\\n 0                                    - New York, NY   \n 1                  - New York, NY 10014 (SoHo area)   \n 2                              - New York, NY 10261   \n 3    - New York, NY 10005 (Financial District area)   \n 4      - New York, NY 10119 (Garment District area)   \n ..                                              ...   \n 964  - New York, NY 10005 (Financial District area)   \n 965          - New York, NY 10017 (Turtle Bay area)   \n 966                                  - New York, NY   \n 967                - New York, NY 10014 (SoHo area)   \n 968                                  - New York, NY   \n \n                                        job_description city  \n 0    About Triplebyte\\nTriplebyte is transforming t...   ny  \n 1    We are looking for a Data Scientist with stron...   ny  \n 2    About Us\\n\\nReady Responders was founded to em...   ny  \n 3    Fakespot is looking for a data scientist to jo...   ny  \n 4    About Biz2Credit (read more at www.biz2credit....   ny  \n ..                                                 ...  ...  \n 964  Fakespot is looking for a data scientist to jo...   ny  \n 965  Overview:\\nDo you love numbers and finding the...   ny  \n 966  Data Science Full-Time Student Opportunity (Gr...   ny  \n 967  We are looking for a Data Scientist with stron...   ny  \n 968  Note: This position is accepting applicants fo...   ny  \n \n [969 rows x 5 columns],\n                                              job_title  \\\n 0                            Machine Learning Engineer   \n 1                                       Data Scientist   \n 2                                       Data Scientist   \n 3                                       Data Scientist   \n 4                   Data Scientist - San Francisco, CA   \n ..                                                 ...   \n 933  Scientist/Machine Learning Engineer, Applied S...   \n 934                                Lead Data Scientist   \n 935                                     Data Scientist   \n 936                                Senior Statistician   \n 937  Engineering Manager, Machine Learning Infrastr...   \n \n                               company  \\\n 0                          Triplebyte   \n 1                      Seen by Indeed   \n 2                       kWh Analytics   \n 3                         YouLand Inc   \n 4    Pacific Gas And Electric Company   \n ..                                ...   \n 933                            Amobee   \n 934                          Esurance   \n 935                       CyberCoders   \n 936                Diati Staffing LLC   \n 937                          DoorDash   \n \n                                          location  \\\n 0          - San Francisco, CA (South Beach area)   \n 1                             - San Francisco, CA   \n 2    - San Francisco, CA 94105 (Yerba Buena area)   \n 3      - San Francisco, CA 94108 (Chinatown area)   \n 4    - San Francisco, CA 94105 (South Beach area)   \n ..                                            ...   \n 933      - Redwood City, CA 94063 (Downtown area)   \n 934  - San Francisco, CA 94105 (South Beach area)   \n 935                           - San Francisco, CA   \n 936                           - San Francisco, CA   \n 937  - San Francisco, CA 94105 (Yerba Buena area)   \n \n                                        job_description city  \n 0    About Triplebyte\\nTriplebyte is transforming t...   sf  \n 1    About Triplebyte\\nTriplebyte is transforming t...   sf  \n 2    ABOUT US\\nBacked by private venture capital an...   sf  \n 3    About YouLand\\nYouLand is a fintech company he...   sf  \n 4    Requisition ID # 25268\\nJob Category : Account...   sf  \n ..                                                 ...  ...  \n 933  About Amobee:\\nThe world’s leading independent...   sf  \n 934  Summary\\nEsurance combines the spunk of a star...   sf  \n 935  Data Scientist\\nWe are a VC funded start-up pa...   sf  \n 936  Duties:\\n· Provide sound experimental design a...   sf  \n 937  Come help us build the world's most reliable o...   sf  \n \n [938 rows x 5 columns],\n                                              job_title  \\\n 0                       Machine Learning Research Lead   \n 1     Python Data Scientist - Research and Engineering   \n 2      Senior Marketing Campaign Data Analyst - 286863   \n 3                                       Data Scientist   \n 4    WiSE Attendees ONLY - Data Scientist, Summer I...   \n ..                                                 ...   \n 262                    Director, Merchandise Analytics   \n 263  Senior Consultant Actuarial, Rewards and Analy...   \n 264                Sr. Applied Scientist, Alexa Speech   \n 265  Director, Name Screening, AML/ATF Models and A...   \n 266  Business Intelligence Specialist/Spécialiste e...   \n \n                             company           location  \\\n 0                    ISG Search Inc      - Toronto, ON   \n 1                   Skynet Software      - Toronto, ON   \n 2                            Procom      - Toronto, ON   \n 3    AMZN CAN Fulfillment Svcs, ULC      - Toronto, ON   \n 4                       Capital One      - Toronto, ON   \n ..                              ...                ...   \n 262                  Walmart Canada  - Mississauga, ON   \n 263                        Deloitte      - Toronto, ON   \n 264  AMZN CAN Fulfillment Svcs, ULC      - Toronto, ON   \n 265                      Scotiabank      - Toronto, ON   \n 266            Air Canada Vacations  - Mississauga, ON   \n \n                                        job_description     city  \n 0    Our client…\\n\\nOur client, a leading financial...  toronto  \n 1    Python Data Scientist - Research and Engineeri...  toronto  \n 2    Senior Marketing Analyst\\nOn behalf of our cli...  toronto  \n 3    Bachelor's Degree\\n5+ years of experience with...  toronto  \n 4    161 Bay Street (93021), Canada, Toronto,Toront...  toronto  \n ..                                                 ...      ...  \n 262  The merchandise analytics team at Walmart Cana...  toronto  \n 263  Job Type: Permanent\\nPrimary Location: Toronto...  toronto  \n 264  Master's degree in Electrical Engineering, Com...  toronto  \n 265  Requisition ID: 63443\\n\\nJoin the Global Commu...  toronto  \n 266  Job Brief\\nBecome the Air Canada Vacations exp...  toronto  \n \n [267 rows x 5 columns],\n                                      job_title  \\\n 0                        Data Scientist Intern   \n 1             Senior Quality Assurance Analyst   \n 2                         Data Engineer Intern   \n 3                      Data Scientist - RACE21   \n 4                      Data Developer - RACE21   \n ..                                         ...   \n 243  Intermediate Accountant (Maternity Leave)   \n 244                 Human Resources Generalist   \n 245                    Data Developer - RACE21   \n 246                             Data Scientist   \n 247               Environmental Lead Scientist   \n \n                              company                                 location  \\\n 0                                                               - Burnaby, BC   \n 1            bioLytical Laboratories                           - Richmond, BC   \n 2                                                             - Vancouver, BC   \n 3             Teck Resources Limited                       - British Columbia   \n 4             Teck Resources Limited                       - British Columbia   \n ..                               ...                                      ...   \n 243               Tantalus Labs Ltd.                          - Vancouver, BC   \n 244            STEMCELL Technologies                          - Vancouver, BC   \n 245           Teck Resources Limited                       - British Columbia   \n 246           Annex Consulting Group  - Metro Vancouver Regional District, BC   \n 247  SynergyAspen Environmental Inc.                         - Port Moody, BC   \n \n                                        job_description       city  \n 0    *This internship is for the summer of 2020*\\n*...  vancouver  \n 1    Senior QA Analyst\\nLocation: Richmond, BC\\nDep...  vancouver  \n 2    *This internship is for the summer of 2020*\\n*...  vancouver  \n 3    Location: Vancouver, BC, CA\\nWith a strong his...  vancouver  \n 4    Location: Vancouver, BC, CA\\nWith a strong his...  vancouver  \n ..                                                 ...        ...  \n 243  The Company\\nTantalus Labs is committed to Sun...  vancouver  \n 244  Job Description Summary\\nThe Human Resources G...  vancouver  \n 245  Location: Vancouver, BC, CA\\nWith a strong his...  vancouver  \n 246  Data Scientist\\n\\nContract- 9 months with exte...  vancouver  \n 247  We are currently recruiting for an Environment...  vancouver  \n \n [248 rows x 5 columns]]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.concat(df_list).reset_index(drop=True)"
   ],
   "metadata": {
    "id": "gXvXnQw5VNva",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288413237,
     "user_tz": -420,
     "elapsed": 7,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "hsc6AJhfV8Rc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288416184,
     "user_tz": -420,
     "elapsed": 14,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "654b38a3-1b07-4eef-845e-4edb5da03c0b"
   },
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        job_title  \\\n0                           Junior Data Scientist   \n1                           Senior Data Scientist   \n2                                  Data Scientist   \n3                                  Data Scientist   \n4     Analyst II/Assistant Director, Data Science   \n...                                           ...   \n4134    Intermediate Accountant (Maternity Leave)   \n4135                   Human Resources Generalist   \n4136                      Data Developer - RACE21   \n4137                               Data Scientist   \n4138                 Environmental Lead Scientist   \n\n                              company  \\\n0                        Pacific Life   \n1                             Invicro   \n2                            Trillium   \n3                       ENGIE Insight   \n4            Liberty Mutual Insurance   \n...                               ...   \n4134               Tantalus Labs Ltd.   \n4135            STEMCELL Technologies   \n4136           Teck Resources Limited   \n4137           Annex Consulting Group   \n4138  SynergyAspen Environmental Inc.   \n\n                                            location  \\\n0                                       - Boston, MA   \n1             - Boston, MA 02210 (South Boston area)   \n2     - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n3                                       - Boston, MA   \n4                                 - Boston, MA 02101   \n...                                              ...   \n4134                                 - Vancouver, BC   \n4135                                 - Vancouver, BC   \n4136                              - British Columbia   \n4137         - Metro Vancouver Regional District, BC   \n4138                                - Port Moody, BC   \n\n                                        job_description       city  \n0     Purpose of Role:\\nAs part of the PLRe Retro Pr...     boston  \n1     Overview:\\nThe Senior Data Scientist will be a...     boston  \n2     Now hiring a Data Scientist in Boston, Massach...     boston  \n3     ENGIE Impact is accelerating sustainability tr...     boston  \n4     Liberty Mutual’s newly formed Global Risk Solu...     boston  \n...                                                 ...        ...  \n4134  The Company\\nTantalus Labs is committed to Sun...  vancouver  \n4135  Job Description Summary\\nThe Human Resources G...  vancouver  \n4136  Location: Vancouver, BC, CA\\nWith a strong his...  vancouver  \n4137  Data Scientist\\n\\nContract- 9 months with exte...  vancouver  \n4138  We are currently recruiting for an Environment...  vancouver  \n\n[4139 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n      <th>company</th>\n      <th>location</th>\n      <th>job_description</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Junior Data Scientist</td>\n      <td>Pacific Life</td>\n      <td>- Boston, MA</td>\n      <td>Purpose of Role:\\nAs part of the PLRe Retro Pr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Senior Data Scientist</td>\n      <td>Invicro</td>\n      <td>- Boston, MA 02210 (South Boston area)</td>\n      <td>Overview:\\nThe Senior Data Scientist will be a...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Scientist</td>\n      <td>Trillium</td>\n      <td>- Boston, MA 02108 (Back Bay-Beacon Hill area)</td>\n      <td>Now hiring a Data Scientist in Boston, Massach...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Scientist</td>\n      <td>ENGIE Insight</td>\n      <td>- Boston, MA</td>\n      <td>ENGIE Impact is accelerating sustainability tr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Analyst II/Assistant Director, Data Science</td>\n      <td>Liberty Mutual Insurance</td>\n      <td>- Boston, MA 02101</td>\n      <td>Liberty Mutual’s newly formed Global Risk Solu...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4134</th>\n      <td>Intermediate Accountant (Maternity Leave)</td>\n      <td>Tantalus Labs Ltd.</td>\n      <td>- Vancouver, BC</td>\n      <td>The Company\\nTantalus Labs is committed to Sun...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4135</th>\n      <td>Human Resources Generalist</td>\n      <td>STEMCELL Technologies</td>\n      <td>- Vancouver, BC</td>\n      <td>Job Description Summary\\nThe Human Resources G...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4136</th>\n      <td>Data Developer - RACE21</td>\n      <td>Teck Resources Limited</td>\n      <td>- British Columbia</td>\n      <td>Location: Vancouver, BC, CA\\nWith a strong his...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4137</th>\n      <td>Data Scientist</td>\n      <td>Annex Consulting Group</td>\n      <td>- Metro Vancouver Regional District, BC</td>\n      <td>Data Scientist\\n\\nContract- 9 months with exte...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4138</th>\n      <td>Environmental Lead Scientist</td>\n      <td>SynergyAspen Environmental Inc.</td>\n      <td>- Port Moody, BC</td>\n      <td>We are currently recruiting for an Environment...</td>\n      <td>vancouver</td>\n    </tr>\n  </tbody>\n</table>\n<p>4139 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBU8_c5rV8_-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288464984,
     "user_tz": -420,
     "elapsed": 10,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "80dcae36-f341-4e29-9a1c-b2b47e30697d"
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4139 entries, 0 to 4138\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   job_title        4139 non-null   object\n",
      " 1   company          4139 non-null   object\n",
      " 2   location         4139 non-null   object\n",
      " 3   job_description  4139 non-null   object\n",
      " 4   city             4139 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 161.8+ KB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjik5WKVWAQX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288446190,
     "user_tz": -420,
     "elapsed": 7,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "a8bc3ecc-ed13-4a24-b1a3-9ea222689527"
   },
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(4139, 5)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "msk = df['city'] == 'la'\n",
    "df.loc[msk, 'city'] = 'los angeles'\n",
    "\n",
    "msk = df['city'] == 'ny'\n",
    "df.loc[msk, 'city'] = 'new york'\n",
    "\n",
    "msk = df['city'] == 'sf'\n",
    "df.loc[msk, 'city'] = 'san francisco'"
   ],
   "metadata": {
    "id": "Zz_K43R9WB6_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288587696,
     "user_tz": -420,
     "elapsed": 3,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset=['job_description', 'city', 'job_title'])\n",
    "print(df.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUD_L2OUWmsi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288631732,
     "user_tz": -420,
     "elapsed": 824,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "161cbd76-3218-44b4-dcbe-4707a1b9e53a"
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4139, 5)\n",
      "(2681, 5)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2thl7bwLWxVx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288745640,
     "user_tz": -420,
     "elapsed": 3,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "80a48cc9-9525-4791-8fa7-8a90662859d7"
   },
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "job_title          0\ncompany            0\nlocation           0\njob_description    0\ncity               0\ndtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "MioX-mSHXlj2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669288846203,
     "user_tz": -420,
     "elapsed": 351,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "4ce67354-7432-4c35-d73d-8652f481e160"
   },
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        job_title  \\\n0                           Junior Data Scientist   \n1                           Senior Data Scientist   \n2                                  Data Scientist   \n3                                  Data Scientist   \n4     Analyst II/Assistant Director, Data Science   \n...                                           ...   \n4132                  Human Resources Coordinator   \n4133                 Technical Sourcing Recruiter   \n4134    Intermediate Accountant (Maternity Leave)   \n4135                   Human Resources Generalist   \n4137                               Data Scientist   \n\n                             company  \\\n0                       Pacific Life   \n1                            Invicro   \n2                           Trillium   \n3                      ENGIE Insight   \n4           Liberty Mutual Insurance   \n...                              ...   \n4132           STEMCELL Technologies   \n4133  AMZN CAN Fulfillment Svcs, ULC   \n4134              Tantalus Labs Ltd.   \n4135           STEMCELL Technologies   \n4137          Annex Consulting Group   \n\n                                            location  \\\n0                                       - Boston, MA   \n1             - Boston, MA 02210 (South Boston area)   \n2     - Boston, MA 02108 (Back Bay-Beacon Hill area)   \n3                                       - Boston, MA   \n4                                 - Boston, MA 02101   \n...                                              ...   \n4132                                 - Vancouver, BC   \n4133                                 - Vancouver, BC   \n4134                                 - Vancouver, BC   \n4135                                 - Vancouver, BC   \n4137         - Metro Vancouver Regional District, BC   \n\n                                        job_description       city  \n0     Purpose of Role:\\nAs part of the PLRe Retro Pr...     boston  \n1     Overview:\\nThe Senior Data Scientist will be a...     boston  \n2     Now hiring a Data Scientist in Boston, Massach...     boston  \n3     ENGIE Impact is accelerating sustainability tr...     boston  \n4     Liberty Mutual’s newly formed Global Risk Solu...     boston  \n...                                                 ...        ...  \n4132  Job Description Summary\\nThe Human Resources C...  vancouver  \n4133  Bachelor’s degree\\nYou have 3+ years of corpor...  vancouver  \n4134  The Company\\nTantalus Labs is committed to Sun...  vancouver  \n4135  Job Description Summary\\nThe Human Resources G...  vancouver  \n4137  Data Scientist\\n\\nContract- 9 months with exte...  vancouver  \n\n[2681 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n      <th>company</th>\n      <th>location</th>\n      <th>job_description</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Junior Data Scientist</td>\n      <td>Pacific Life</td>\n      <td>- Boston, MA</td>\n      <td>Purpose of Role:\\nAs part of the PLRe Retro Pr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Senior Data Scientist</td>\n      <td>Invicro</td>\n      <td>- Boston, MA 02210 (South Boston area)</td>\n      <td>Overview:\\nThe Senior Data Scientist will be a...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Scientist</td>\n      <td>Trillium</td>\n      <td>- Boston, MA 02108 (Back Bay-Beacon Hill area)</td>\n      <td>Now hiring a Data Scientist in Boston, Massach...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Scientist</td>\n      <td>ENGIE Insight</td>\n      <td>- Boston, MA</td>\n      <td>ENGIE Impact is accelerating sustainability tr...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Analyst II/Assistant Director, Data Science</td>\n      <td>Liberty Mutual Insurance</td>\n      <td>- Boston, MA 02101</td>\n      <td>Liberty Mutual’s newly formed Global Risk Solu...</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4132</th>\n      <td>Human Resources Coordinator</td>\n      <td>STEMCELL Technologies</td>\n      <td>- Vancouver, BC</td>\n      <td>Job Description Summary\\nThe Human Resources C...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4133</th>\n      <td>Technical Sourcing Recruiter</td>\n      <td>AMZN CAN Fulfillment Svcs, ULC</td>\n      <td>- Vancouver, BC</td>\n      <td>Bachelor’s degree\\nYou have 3+ years of corpor...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4134</th>\n      <td>Intermediate Accountant (Maternity Leave)</td>\n      <td>Tantalus Labs Ltd.</td>\n      <td>- Vancouver, BC</td>\n      <td>The Company\\nTantalus Labs is committed to Sun...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4135</th>\n      <td>Human Resources Generalist</td>\n      <td>STEMCELL Technologies</td>\n      <td>- Vancouver, BC</td>\n      <td>Job Description Summary\\nThe Human Resources G...</td>\n      <td>vancouver</td>\n    </tr>\n    <tr>\n      <th>4137</th>\n      <td>Data Scientist</td>\n      <td>Annex Consulting Group</td>\n      <td>- Metro Vancouver Regional District, BC</td>\n      <td>Data Scientist\\n\\nContract- 9 months with exte...</td>\n      <td>vancouver</td>\n    </tr>\n  </tbody>\n</table>\n<p>2681 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['job_description'].iloc[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "toej-3IZXl1J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669295327868,
     "user_tz": -420,
     "elapsed": 384,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "5c022eb3-13a5-4b00-8fa8-4114ff1adb42"
   },
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'Overview:\\nThe Senior Data Scientist will be an imperative member of Invicro’s growing AI Team. We are looking for well-organized, talented people with a deep knowledge in programming, data processing, automation, statistics and machine learning. The Senior Data Scientist uses mathematics, statistics, modeling, analysis, and technology to transform high volumes of complex imaging data into advanced, interpretable analytic solutions.\\n\\nResponsibilities:\\nDrive the collection, organization, coordination and governance around internal and external data resources.\\nDevelops, maintains, and collects structured and unstructured data sets for analysis and reporting.\\nCreative thinking in reports, projections, models, and presentations to support Invicro’s Imaging Analysis strategy and AI initiative.\\nProvide influence on department strategy around data science and machine learning.\\nMaintain awareness of the resources and advances in artificial intelligence applied to biomedical problems, in particular resources relevant to pathology, neurology or drug development.\\nDevelop and maintain unit and system-level regression testing.\\nContribute to collaborative science incorporating machine learning / AI into clinical goals.\\nDevelop and verify easy to use reference datasets that facilitate machine learning/AI research, testing and application deployment\\nMentor junior data scientists.\\n\\nQualifications/Skills:\\nMaster’s degree in Data Science or related field with 3-5+ years of industry or academic experience\\nDirect experience in an Engineering / Data Science environment preferred\\n5+ years of programming/scripting experience with a variety of languages including but not limited to python, R and C++. The ability to program with keras and the low-level tensor flow API.\\nDeep, practical knowledge of using the training, testing and validation paradigm to drive progress\\nDemonstrated commitment to reusable/repurposable data organization and software\\nStrong intuitions about data modeling and testing and how to overcome common obstacles\\nIn-depth knowledge of a biomedical or scientific application area and experience with applying deep learning to problems in this area\\n\\nInvicro is an equal opportunities employer and positively encourages applications from suitably qualified and eligible candidates regardless of sex, race, disability, age, sexual orientation, gender reassignment, religion or belief, marital status, or pregnancy and maternity.'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "word_tokenize(str(df['job_description'].iloc[12]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h799qKVbbTTW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290146261,
     "user_tz": -420,
     "elapsed": 4,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "1a0b8daf-383b-4ab8-a2c5-6e221006fe8f"
   },
   "execution_count": 40,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/home/vutuyen/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mword_tokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjob_description\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py:129\u001B[0m, in \u001B[0;36mword_tokenize\u001B[0;34m(text, language, preserve_line)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mword_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m, preserve_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    Return a tokenized copy of *text*,\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended word tokenizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    :type preserve_line: bool\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 129\u001B[0m     sentences \u001B[38;5;241m=\u001B[39m [text] \u001B[38;5;28;01mif\u001B[39;00m preserve_line \u001B[38;5;28;01melse\u001B[39;00m \u001B[43msent_tokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m    131\u001B[0m         token \u001B[38;5;28;01mfor\u001B[39;00m sent \u001B[38;5;129;01min\u001B[39;00m sentences \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m _treebank_word_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(sent)\n\u001B[1;32m    132\u001B[0m     ]\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py:106\u001B[0m, in \u001B[0;36msent_tokenize\u001B[0;34m(text, language)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msent_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    :param language: the model name in the Punkt corpus\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtokenizers/punkt/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlanguage\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.pickle\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:750\u001B[0m, in \u001B[0;36mload\u001B[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001B[0m\n\u001B[1;32m    747\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<<Loading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresource_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    749\u001B[0m \u001B[38;5;66;03m# Load the resource.\u001B[39;00m\n\u001B[0;32m--> 750\u001B[0m opened_resource \u001B[38;5;241m=\u001B[39m \u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresource_url\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    753\u001B[0m     resource_val \u001B[38;5;241m=\u001B[39m opened_resource\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:876\u001B[0m, in \u001B[0;36m_open\u001B[0;34m(resource_url)\u001B[0m\n\u001B[1;32m    873\u001B[0m protocol, path_ \u001B[38;5;241m=\u001B[39m split_resource_url(resource_url)\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m protocol \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnltk\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mopen()\n\u001B[1;32m    877\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001B[39;00m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m find(path_, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mopen()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    581\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[1;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/home/vutuyen/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tool_keywords1 = ['python', 'pytorch', 'sql', 'mxnet', 'mlflow', 'einstein', 'theano', 'pyspark', 'solr', 'mahout', \n",
    " 'cassandra', 'aws', 'powerpoint', 'spark', 'pig', 'sas', 'java', 'nosql', 'docker', 'salesforce', 'scala', 'r',\n",
    " 'c', 'c++', 'net', 'tableau', 'pandas', 'scikitlearn', 'sklearn', 'matlab', 'scala', 'keras', 'tensorflow', 'clojure',\n",
    " 'caffe', 'scipy', 'numpy', 'matplotlib', 'vba', 'spss', 'linux', 'azure', 'cloud', 'gcp', 'mongodb', 'mysql', 'oracle', \n",
    " 'redshift', 'snowflake', 'kafka', 'javascript', 'qlik', 'jupyter', 'perl', 'bigquery', 'unix', 'react',\n",
    " 'scikit', 'powerbi', 's3', 'ec2', 'lambda', 'ssrs', 'kubernetes', 'hana', 'spacy', 'tf', 'django', 'sagemaker',\n",
    " 'seaborn', 'mllib', 'github', 'git', 'elasticsearch', 'splunk', 'airflow', 'looker', 'rapidminer', 'birt', 'pentaho', \n",
    " 'jquery', 'nodejs', 'd3', 'plotly', 'bokeh', 'xgboost', 'rstudio', 'shiny', 'dash', 'h20', 'h2o', 'hadoop', 'mapreduce', \n",
    " 'hive', 'cognos', 'angular', 'nltk', 'flask', 'node', 'firebase', 'bigtable', 'rust', 'php', 'cntk', 'lightgbm', \n",
    " 'kubeflow', 'rpython', 'unixlinux', 'postgressql', 'postgresql', 'postgres', 'hbase', 'dask', 'ruby', 'julia', 'tensor',\n",
    "# added r packages doesn't seem to impact the result\n",
    " 'dplyr','ggplot2','esquisse','bioconductor','shiny','lubridate','knitr','mlr','quanteda','dt','rcrawler','caret','rmarkdown',\n",
    " 'leaflet','janitor','ggvis','plotly','rcharts','rbokeh','broom','stringr','magrittr','slidify','rvest',\n",
    " 'rmysql','rsqlite','prophet','glmnet','text2vec','snowballc','quantmod','rstan','swirl','datasciencer']\n",
    "\n",
    "\n",
    "tool_keywords2 = set(['amazon web services', 'google cloud', 'sql server'])\n",
    "\n",
    "skill_keywords1 = set(['statistics', 'cleansing', 'chatbot', 'cleaning', 'blockchain', 'causality', 'correlation', 'bandit', 'anomaly', 'kpi',\n",
    " 'dashboard', 'geospatial', 'ocr', 'econometrics', 'pca', 'gis', 'svm', 'svd', 'tuning', 'hyperparameter', 'hypothesis',\n",
    " 'salesforcecom', 'segmentation', 'biostatistics', 'unsupervised', 'supervised', 'exploratory',\n",
    " 'recommender', 'recommendations', 'research', 'sequencing', 'probability', 'reinforcement', 'graph', 'bioinformatics',\n",
    " 'chi', 'knn', 'outlier', 'etl', 'normalization', 'classification', 'optimizing', 'prediction', 'forecasting',\n",
    " 'clustering', 'cluster', 'optimization', 'visualization', 'nlp', 'c#',\n",
    " 'regression', 'logistic', 'nn', 'cnn', 'glm',\n",
    " 'rnn', 'lstm', 'gbm', 'boosting', 'recurrent', 'convolutional', 'bayesian',\n",
    " 'bayes'])\n",
    "\n",
    "\n",
    "skill_keywords2 = set(['random forest', 'natural language processing', 'machine learning', 'decision tree', 'deep learning', 'experimental design',\n",
    " 'time series', 'nearest neighbors', 'neural network', 'support vector machine', 'computer vision', 'machine vision', 'dimensionality reduction', \n",
    " 'text analytics', 'power bi', 'a/b testing', 'ab testing', 'chat bot', 'data mining'])\n",
    "\n",
    "\n",
    "degree_dict = {'bs': 1, 'bachelor': 1, 'undergraduate': 1, \n",
    "               'master': 2, 'graduate': 2, 'mba': 2.5, \n",
    "               'phd': 3, 'ph.d': 3, 'ba': 1, 'ma': 2,\n",
    "               'postdoctoral': 4, 'postdoc': 4, 'doctorate': 3}\n",
    "\n",
    "\n",
    "degree_dict2 = {'advanced degree': 2, 'ms or': 2, 'ms degree': 2, '4 year degree': 1, 'bs/': 1, 'ba/': 1,\n",
    "                '4-year degree': 1, 'b.s.': 1, 'm.s.': 2, 'm.s': 2, 'b.s': 1, 'phd/': 3, 'ph.d.': 3, 'ms/': 2,\n",
    "                'm.s/': 2, 'm.s./': 2, 'msc/': 2, 'master/': 2, 'master\\'s/': 2, 'bachelor\\s/': 1}\n",
    "degree_keywords2 = set(degree_dict2.keys())"
   ],
   "metadata": {
    "id": "JrFOSjl5bYr3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290188197,
     "user_tz": -420,
     "elapsed": 373,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pos_tag(tool_keywords1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7_4EUvYctk5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290199636,
     "user_tz": -420,
     "elapsed": 454,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "01954fe3-21ba-4fa1-831d-080f1cb73de7"
   },
   "execution_count": 42,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93maveraged_perceptron_tagger\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001B[0m\n\n  Searched in:\n    - '/home/vutuyen/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [42], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pos_tag\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstem\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PorterStemmer\n\u001B[0;32m----> 4\u001B[0m \u001B[43mpos_tag\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtool_keywords1\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/tag/__init__.py:165\u001B[0m, in \u001B[0;36mpos_tag\u001B[0;34m(tokens, tagset, lang)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpos_tag\u001B[39m(tokens, tagset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meng\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;124;03m    tag the given list of tokens.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    :rtype: list(tuple(str, str))\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 165\u001B[0m     tagger \u001B[38;5;241m=\u001B[39m \u001B[43m_get_tagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlang\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/tag/__init__.py:107\u001B[0m, in \u001B[0;36m_get_tagger\u001B[0;34m(lang)\u001B[0m\n\u001B[1;32m    105\u001B[0m     tagger\u001B[38;5;241m.\u001B[39mload(ap_russian_model_loc)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 107\u001B[0m     tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPerceptronTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tagger\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/tag/perceptron.py:167\u001B[0m, in \u001B[0;36mPerceptronTagger.__init__\u001B[0;34m(self, load)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load:\n\u001B[1;32m    166\u001B[0m     AP_MODEL_LOC \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\n\u001B[0;32m--> 167\u001B[0m         \u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtaggers/averaged_perceptron_tagger/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mPICKLE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    168\u001B[0m     )\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload(AP_MODEL_LOC)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    581\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[1;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93maveraged_perceptron_tagger\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001B[0m\n\n  Searched in:\n    - '/home/vutuyen/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "# process the job description.\n",
    "def prepare_job_desc(desc):\n",
    "    # tokenize description.\n",
    "    tokens = word_tokenize(desc)\n",
    "        \n",
    "    # Parts of speech (POS) tag tokens.\n",
    "    token_tag = pos_tag(tokens)\n",
    "    include_tags = ['VBN', 'VBD', 'JJ', 'JJS', 'JJR', 'CD', 'NN', 'NNS', 'NNP', 'NNPS']\n",
    "    filtered_tokens = [tok for tok, tag in token_tag if tag in include_tags]\n",
    "    \n",
    "    # stem words.\n",
    "    stemmed_tokens = [ps.stem(tok).lower() for tok in filtered_tokens]\n",
    "    return set(stemmed_tokens)\n",
    "\n",
    "df['job_description_word_set'] = df['job_description'].map(prepare_job_desc)\n",
    "\n",
    "# process the keywords\n",
    "tool_keywords1_set = set([ps.stem(tok) for tok in tool_keywords1]) # stem the keywords (since the job description is also stemmed.)\n",
    "tool_keywords1_dict = {ps.stem(tok):tok for tok in tool_keywords1} # use this dictionary to revert the stemmed words back to the original.\n",
    "\n",
    "skill_keywords1_set = set([ps.stem(tok) for tok in skill_keywords1])\n",
    "skill_keywords1_dict = {ps.stem(tok):tok for tok in skill_keywords1}\n",
    "\n",
    "degree_keywords1_set = set([ps.stem(tok) for tok in degree_dict.keys()])\n",
    "degree_keywords1_dict = {ps.stem(tok):tok for tok in degree_dict.keys()}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVvshAjAcwMZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669293888773,
     "user_tz": -420,
     "elapsed": 125102,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "6eafb961-f09f-4d08-ea2c-b01a827a839c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tool_keywords1_dict"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mIsiaql0NGR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669296347549,
     "user_tz": -420,
     "elapsed": 362,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "99773c84-0efb-4cad-92e5-3988f6504862"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['job_description_word_set'].iloc[10]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCiPlzNmc6fw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290364461,
     "user_tz": -420,
     "elapsed": 10,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "44659e4f-c182-489c-9dad-a7331fc76f59"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tool_list = []\n",
    "skill_list = []\n",
    "degree_list = []\n",
    "\n",
    "msk = df['city'] != '' \n",
    "\n",
    "num_postings = len(df[msk].index)\n",
    "for i in range(num_postings):\n",
    "    job_desc = df[msk].iloc[i]['job_description'].lower()\n",
    "    job_desc_set = df[msk].iloc[i]['job_description_word_set']\n",
    "    \n",
    "    # check if the keywords are in the job description. Look for exact match by token.\n",
    "    tool_words = tool_keywords1_set.intersection(job_desc_set)\n",
    "    skill_words = skill_keywords1_set.intersection(job_desc_set)\n",
    "    degree_words = degree_keywords1_set.intersection(job_desc_set)\n",
    "    \n",
    "    # check if longer keywords (more than one word) are in the job description. Match by substring.\n",
    "    j = 0\n",
    "    for tool_keyword2 in tool_keywords2:\n",
    "        # tool keywords.\n",
    "        if tool_keyword2 in job_desc:\n",
    "            tool_list.append(tool_keyword2)\n",
    "            j += 1\n",
    "    \n",
    "    k = 0\n",
    "    for skill_keyword2 in skill_keywords2:\n",
    "        # skill keywords.\n",
    "        if skill_keyword2 in job_desc:\n",
    "            skill_list.append(skill_keyword2)\n",
    "            k += 1\n",
    "    \n",
    "    # search for the minimum education.\n",
    "    min_education_level = 999\n",
    "    for degree_word in degree_words:\n",
    "        level = degree_dict[degree_keywords1_dict[degree_word]]\n",
    "        min_education_level = min(min_education_level, level)\n",
    "    \n",
    "    for degree_keyword2 in degree_keywords2:\n",
    "        # longer keywords. Match by substring.\n",
    "        if degree_keyword2 in job_desc:\n",
    "            level = degree_dict2[degree_keyword2]\n",
    "            min_education_level = min(min_education_level, level)\n",
    "    \n",
    "    # label the job descriptions without any tool keywords.\n",
    "    if len(tool_words) == 0 and j == 0:\n",
    "        tool_list.append('nothing specified')\n",
    "    \n",
    "    # label the job descriptions without any skill keywords.\n",
    "    if len(skill_words) == 0 and k == 0:\n",
    "        skill_list.append('nothing specified')\n",
    "    \n",
    "    # If none of the keywords were found, but the word degree is present, then assume it's a bachelors level.\n",
    "    if min_education_level > 500:\n",
    "        if 'degree' in job_desc:\n",
    "            min_education_level = 1\n",
    "    \n",
    "    tool_list += list(tool_words)\n",
    "    skill_list += list(skill_words)\n",
    "    degree_list.append(min_education_level)"
   ],
   "metadata": {
    "id": "8qeceFkEc8pi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tool_words"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPuRYyoi1xc6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669296760921,
     "user_tz": -420,
     "elapsed": 5,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "0791adc2-4011-47cd-ca7c-482a069f2224"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tool_list"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_Acvg5e1nnA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669296799515,
     "user_tz": -420,
     "elapsed": 379,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "4619b9a6-614a-4773-a809-8104d4c49702"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Visualizing the Results"
   ],
   "metadata": {
    "id": "7nzJdQv4erve"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Top Tools In-Demand"
   ],
   "metadata": {
    "id": "CwrlvYDeeuXO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create the list of tools.\n",
    "df_tool = pd.DataFrame(data={'cnt': tool_list})\n",
    "df_tool = df_tool.replace(tool_keywords1_dict)\n",
    "\n",
    "# group some of the categories together.\n",
    "msk = df_tool['cnt'] == 'h20'\n",
    "df_tool.loc[msk, 'cnt'] = 'h2o'\n",
    "\n",
    "msk = df_tool['cnt'] == 'aws'\n",
    "df_tool.loc[msk, 'cnt'] = 'amazon web services'\n",
    "\n",
    "msk = df_tool['cnt'] == 'gcp'\n",
    "df_tool.loc[msk, 'cnt'] = 'google cloud'\n",
    "\n",
    "msk = df_tool['cnt'] == 'github'\n",
    "df_tool.loc[msk, 'cnt'] = 'git'\n",
    "\n",
    "msk = df_tool['cnt'] == 'postgressql'\n",
    "df_tool.loc[msk, 'cnt'] = 'postgres'\n",
    "\n",
    "msk = df_tool['cnt'] == 'tensor'\n",
    "df_tool.loc[msk, 'cnt'] = 'tensorflow'\n",
    "\n",
    "df_tool_top50 = df_tool['cnt'].value_counts().reset_index().rename(columns={'index': 'tool'}).iloc[:50]"
   ],
   "metadata": {
    "id": "lfFkg8MCd2oy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669291006617,
     "user_tz": -420,
     "elapsed": 431,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_tool_top50"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CfCY5voqf5Cn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669297034102,
     "user_tz": -420,
     "elapsed": 9,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "153bc4d4-304c-4b68-946b-ba55cf970ba8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualize the tools.\n",
    "layout = dict(\n",
    "    title='Tools For Data Scientists',\n",
    "    yaxis=dict(\n",
    "        title='% of job postings',\n",
    "        tickformat=',.0%',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=df_tool_top50['tool'],\n",
    "    y=df_tool_top50['cnt']/num_postings\n",
    "))\n",
    "\n",
    "# iplot(fig)\n",
    "fig.show(renderer=\"colab\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "NL-9WL1seYQA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669292084345,
     "user_tz": -420,
     "elapsed": 10,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "1fbe2d73-276d-4504-ffcf-9ea4baf13e17"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Top Skills In-Demand"
   ],
   "metadata": {
    "id": "AQ5iPqzsexbO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create the list of skills/knowledge.\n",
    "df_skills = pd.DataFrame(data={'cnt': skill_list})\n",
    "df_skills = df_skills.replace(skill_keywords1_dict)\n",
    "\n",
    "# group some of the categories together.\n",
    "msk = df_skills['cnt'] == 'nlp'\n",
    "df_skills.loc[msk, 'cnt'] = 'natural language processing'\n",
    "\n",
    "msk = df_skills['cnt'] == 'convolutional'\n",
    "df_skills.loc[msk, 'cnt'] = 'convolutional neural network'\n",
    "\n",
    "msk = df_skills['cnt'] == 'cnn'\n",
    "df_skills.loc[msk, 'cnt'] = 'convolutional neural network'\n",
    "\n",
    "msk = df_skills['cnt'] == 'recurrent'\n",
    "df_skills.loc[msk, 'cnt'] = 'recurrent neural network'\n",
    "\n",
    "msk = df_skills['cnt'] == 'rnn'\n",
    "df_skills.loc[msk, 'cnt'] = 'recurrent neural network'\n",
    "\n",
    "msk = df_skills['cnt'] == 'knn'\n",
    "df_skills.loc[msk, 'cnt'] = 'nearest neighbors'\n",
    "\n",
    "msk = df_skills['cnt'] == 'svm'\n",
    "df_skills.loc[msk, 'cnt'] = 'support vector machine'\n",
    "\n",
    "msk = df_skills['cnt'] == 'machine vision'\n",
    "df_skills.loc[msk, 'cnt'] = 'computer vision'\n",
    "\n",
    "msk = df_skills['cnt'] == 'ab testing'\n",
    "df_skills.loc[msk, 'cnt'] = 'a/b testing'\n",
    "\n",
    "df_skills_top50 = df_skills['cnt'].value_counts().reset_index().rename(columns={'index': 'skill'}).iloc[:50]\n"
   ],
   "metadata": {
    "id": "5HixGDi9ebDx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290666083,
     "user_tz": -420,
     "elapsed": 353,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualize the skills.\n",
    "layout = dict(\n",
    "    title='Skills For Data Scientists',\n",
    "    yaxis=dict(\n",
    "        title='% of job postings',\n",
    "        tickformat=',.0%',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=df_skills_top50['skill'],\n",
    "    y=df_skills_top50['cnt']/num_postings\n",
    "))\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "BKSyN8aWeiPB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669292112428,
     "user_tz": -420,
     "elapsed": 406,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "06adf702-72f3-4d4a-d32c-03730759ce81"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Minimum Education Required"
   ],
   "metadata": {
    "id": "8t1GutuIe06v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create the list of degree.\n",
    "df_degrees = pd.DataFrame(data={'cnt': degree_list})\n",
    "df_degrees['degree_type'] = ''\n",
    "\n",
    "\n",
    "msk = df_degrees['cnt'] == 1\n",
    "df_degrees.loc[msk, 'degree_type'] = 'bachelors'\n",
    "\n",
    "msk = df_degrees['cnt'] == 2\n",
    "df_degrees.loc[msk, 'degree_type'] = 'masters'\n",
    "\n",
    "msk = df_degrees['cnt'] == 3\n",
    "df_degrees.loc[msk, 'degree_type'] = 'phd'\n",
    "\n",
    "msk = df_degrees['cnt'] == 4\n",
    "df_degrees.loc[msk, 'degree_type'] = 'postdoc'\n",
    "\n",
    "msk = df_degrees['cnt'] == 2.5\n",
    "df_degrees.loc[msk, 'degree_type'] = 'mba'\n",
    "\n",
    "msk = df_degrees['cnt'] > 500\n",
    "df_degrees.loc[msk, 'degree_type'] = 'not specified'\n",
    "\n",
    "\n",
    "df_degree_cnt = df_degrees['degree_type'].value_counts().reset_index().rename(columns={'index': 'degree'}).iloc[:50]"
   ],
   "metadata": {
    "id": "lvvSCMrRej7X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669290762100,
     "user_tz": -420,
     "elapsed": 412,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualize the degrees.\n",
    "layout = dict(\n",
    "    title='Minimum Education For Data Scientists',\n",
    "    yaxis=dict(\n",
    "        title='% of job postings',\n",
    "        tickformat=',.0%',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=df_degree_cnt['degree'],\n",
    "    y=df_degree_cnt['degree_type']/num_postings\n",
    "))\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "VuDGSeSKe5se",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669292109715,
     "user_tz": -420,
     "elapsed": 5,
     "user": {
      "displayName": "hiu1 hiu",
      "userId": "17621348449349376381"
     }
    },
    "outputId": "cd3a1f02-0cb1-4394-d836-cf7d3cc3f46d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SoKBZa6Ue7c8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
