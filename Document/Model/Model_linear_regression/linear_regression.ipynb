{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height (cm)\n",
    "X = np.array(\n",
    "    [[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]]).T\n",
    "# weight (kg)\n",
    "y = np.array([[49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68]]).T\n",
    "# Visualize data\n",
    "plt.plot(X, y, 'ro')\n",
    "plt.axis([140, 190, 45, 75])\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Xbar\n",
    "one = np.ones((X.shape[0], 1))\n",
    "Xbar = np.concatenate((one, X), axis=1)\n",
    "\n",
    "# Calculating weights of the fitting line\n",
    "A = np.dot(Xbar.T, Xbar)\n",
    "b = np.dot(Xbar.T, y)\n",
    "w = np.dot(np.linalg.pinv(A), b)\n",
    "print('w = ', w)\n",
    "# Preparing the fitting line\n",
    "w_0 = w[0][0]\n",
    "w_1 = w[1][0]\n",
    "\n",
    "x0 = np.linspace(145, 185, 2, endpoint=True)\n",
    "y0 = w_0 + w_1*x0\n",
    "\n",
    "print(w_0, w_1)\n",
    "# Drawing the fitting line\n",
    "plt.plot(X.T, y.T, 'ro')     # data\n",
    "plt.plot(x0, y0)               # the fitting line\n",
    "plt.axis([140, 190, 45, 75])\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# fit the model by Linear Regression\n",
    "# fit_intercept = False for calculating the bias\n",
    "regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(Xbar, y)\n",
    "\n",
    "print(u'Nghiệm tìm được bằng scikit-learn  : ', regr.coef_)\n",
    "w_0 = regr.coef_[0][0]\n",
    "w_1 = regr.coef_[0][1]\n",
    "print(w_0, w_1)\n",
    "x0 = np.linspace(145, 185, 2, endpoint=True)\n",
    "y0 = w_0 + w_1*x0\n",
    "\n",
    "# Drawing the fitting line\n",
    "plt.plot(X.T, y.T, 'ro')     # data\n",
    "plt.plot(x0, y0)               # the fitting line\n",
    "plt.axis([140, 190, 45, 75])\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# height (cm)\n",
    "X = np.array([[147, 150, 153, 158, 163, 165, 168,\n",
    "             170, 173, 175, 178, 180, 183, 150]]).T\n",
    "# weight (kg)\n",
    "y = np.array([[49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68, 90]]).T\n",
    "\n",
    "# Building Xbar\n",
    "one = np.ones((X.shape[0], 1))\n",
    "Xbar = np.concatenate((one, X), axis=1)\n",
    "\n",
    "# Calculating weights of the fitting line\n",
    "A = np.dot(Xbar.T, Xbar)\n",
    "b = np.dot(Xbar.T, y)\n",
    "w = np.dot(np.linalg.pinv(A), b)\n",
    "print('w = ', w)\n",
    "# Preparing the fitting line\n",
    "w_0 = w[0][0]\n",
    "w_1 = w[1][0]\n",
    "x0 = np.linspace(145, 185, 2, endpoint=True)\n",
    "y0 = w_0 + w_1*x0\n",
    "\n",
    "# Drawing the fitting line\n",
    "plt.plot(X, y, 'ro')     # data\n",
    "plt.plot(x0, y0)               # the fitting line\n",
    "plt.axis([140, 190, 45, 95])\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Train_samsung.csv')\n",
    "df_test = pd.read_csv(\"./Test_samsung_noclass.csv\")\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(dataframe: pd.DataFrame):\n",
    "    print(tabulate(dataframe, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_df(dataframe=df_train)\n",
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Nan_values(df: pd.DataFrame):\n",
    "    for key in df.keys():\n",
    "        if df[key].isnull().sum() > 0:\n",
    "            print(key, df[key].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberic(dataframe: pd.DataFrame):\n",
    "    df = dataframe.copy()\n",
    "    for key in df.keys():\n",
    "        if df[key].dtype == object:\n",
    "            df[key] = LabelEncoder().fit_transform(df[key])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normailize(dataframe: pd.DataFrame):\n",
    "    df = dataframe.copy()\n",
    "    for key in df.keys():\n",
    "        if df[key].dtype != object:\n",
    "            min = df[key].min()\n",
    "            max = df[key].max()\n",
    "            df[key] = (df[key] - min)/(max-min)\n",
    "            df[key] = df[key].round(decimals=4)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_Nan_values(df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = normailize(dataframe=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = numberic(dataframe=df_train)\n",
    "# print_df(dataframe=df_train)\n",
    "display(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outliers(dataframe: pd.DataFrame):\n",
    "    df = dataframe.copy()\n",
    "    for key in df.keys():\n",
    "        if key != 'Class':\n",
    "            q1 = df[key].quantile(0.25)\n",
    "            q3 = df[key].quantile(0.75)\n",
    "            iqr = q3-q1\n",
    "            Lower_tail = q1 - 1.5 * iqr\n",
    "            Upper_tail = q3 + 1.5 * iqr\n",
    "            if Lower_tail != Upper_tail:\n",
    "                df = df.drop(df[df[key] > Upper_tail].index)\n",
    "                df = df.drop(df[df[key] < Lower_tail].index)\n",
    "            print(key)\n",
    "            print(f\"Lower_tail: {Lower_tail}\")\n",
    "            print(f\"Upper_tail: {Upper_tail}\")\n",
    "            print(\"\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = iqr_outliers(dataframe=data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_df(data_train)\n",
    "display(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_train.keys():\n",
    "    display(data_train[key].agg(['mean', 'median', 'std'], axis='rows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_Nan_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = dataframe.copy()\n",
    "    for key in df.keys():\n",
    "        if df[key].isnull().sum() > 0:\n",
    "            df[key].fillna(round(df[key].median()), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = replace_Nan_data(dataframe=data_train)\n",
    "# print_df(dataframe=data_train)\n",
    "display(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_Nan_values(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.corr(), annot=True, cmap='RdYlGn',\n",
    "            linewidths=0.2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "scoring = ['accuracy', 'f1']\n",
    "\n",
    "pipeLine = make_pipeline(standard_scaler, logit)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "cv_resutls = cross_validate(\n",
    "    pipeLine, data_train, labels_train, cv=kf, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "cv_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_resutls['test_f1'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
